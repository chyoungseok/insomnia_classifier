{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom Dataset 생성\n",
    "class FakePPGDataset(Dataset):\n",
    "    def __init__(self, num_samples=1000, signal_length=250, num_classes=2, sampling_rate=34):\n",
    "        np.random.seed(42)\n",
    "        self.num_samples = num_samples\n",
    "        self.signal_length = signal_length\n",
    "        self.num_classes = num_classes\n",
    "        self.sampling_rate = sampling_rate\n",
    "\n",
    "        # 가짜 PPG 데이터 생성 (정규 분포)\n",
    "        self.data = np.random.normal(0, 1, (num_samples, signal_length))\n",
    "        \n",
    "        # 라벨 생성 (0 또는 1)\n",
    "        self.labels = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        # PyTorch 텐서로 변환\n",
    "        return torch.tensor(signal, dtype=torch.float32).unsqueeze(0), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_dataset = FakePPGDataset(num_samples=800)\n",
    "test_dataset = FakePPGDataset(num_samples=200)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleSleepPPGModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):  # num_classes는 분류할 클래스 수\n",
    "        super(SimpleSleepPPGModel, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Batch Normalization\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        # MaxPooling Layers\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(64 * 62, 128)  # 조정된 입력 크기 (64 feature maps, 길이 62로 감소)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional Layers with ReLU, BatchNorm, and MaxPooling\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # Conv1 -> ReLU -> BatchNorm -> MaxPooling\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # Conv2 -> ReLU -> BatchNorm -> MaxPooling\n",
    "        x = F.relu(self.bn3(self.conv3(x)))            # Conv3 -> ReLU -> BatchNorm (마지막 레이어는 Pooling 생략 가능)\n",
    "        \n",
    "        # Flattening\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))  # Fully Connected Layer + ReLU\n",
    "        x = self.dropout(x)      # Dropout\n",
    "        x = self.fc2(x)          # Output Layer (분류)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.8155\n",
      "Epoch [2/10], Loss: 0.6540\n",
      "Epoch [3/10], Loss: 0.6317\n",
      "Epoch [4/10], Loss: 0.5485\n",
      "Epoch [5/10], Loss: 0.4614\n",
      "Epoch [6/10], Loss: 0.3752\n",
      "Epoch [7/10], Loss: 0.2588\n",
      "Epoch [8/10], Loss: 0.1772\n",
      "Epoch [9/10], Loss: 0.1106\n",
      "Epoch [10/10], Loss: 0.0790\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 초기화\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleSleepPPGModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for signals, labels in train_loader:\n",
    "        signals, labels = signals.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(signals)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 250])\n",
      "torch.Size([32, 1, 250])\n",
      "torch.Size([32, 1, 250])\n",
      "torch.Size([32, 1, 250])\n",
      "torch.Size([32, 1, 250])\n",
      "torch.Size([32, 1, 250])\n",
      "torch.Size([8, 1, 250])\n",
      "Accuracy on test data: 47.00%\n",
      "Predicted class for the new sample: 0\n"
     ]
    }
   ],
   "source": [
    "# 테스트 루프\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for signals, labels in test_loader:\n",
    "        signals, labels = signals.to(device), labels.to(device)\n",
    "        print(signals.shape)\n",
    "        outputs = model(signals)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test data: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# 새로운 샘플에 대한 예측\n",
    "new_sample = torch.randn(1, 1, 250).to(device)  # 임의의 신호 입력\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(new_sample)\n",
    "    predicted_class = torch.argmax(prediction, dim=1).item()\n",
    "print(f\"Predicted class for the new sample: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5403, -0.4740],\n",
       "        [-2.3342,  3.8923],\n",
       "        [-1.8329,  2.1931],\n",
       "        [-2.4807,  3.5390],\n",
       "        [-2.0745,  2.6978],\n",
       "        [ 3.1771, -1.6116],\n",
       "        [ 1.7548, -0.8408],\n",
       "        [ 2.5300, -0.8827]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ins_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
