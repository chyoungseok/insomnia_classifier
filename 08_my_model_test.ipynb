{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading ... done !\n"
     ]
    }
   ],
   "source": [
    "from my_dataset import gen_dataset\n",
    "from my_model import SimpleSleepPPGModel\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "# 데이터셋 준비\n",
    "print(\"Data loading ... \", end='')\n",
    "full_dataset = gen_dataset(train_or_test='default')\n",
    "print(\"done !\")\n",
    "\n",
    "# Train, Validation, Test Split\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size  # 나머지는 test에 할당\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "batch_size = 4\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=generator1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, generator=generator1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from my_model import SimpleSleepPPGModel\n",
    "\n",
    "cnt_0 = 0\n",
    "cnt_1 = 0\n",
    "\n",
    "for signal, label in train_loader:\n",
    "    pass\n",
    "\n",
    "# 모델 초기화\n",
    "device = torch.device(\"cuda\")\n",
    "model = SimpleSleepPPGModel().to(device)\n",
    "signal_torch = signal.to(device)\n",
    "label_torch = label.to(device)\n",
    "\n",
    "predicted_label = model(signal_torch)\n",
    "\n",
    "_, predicted_label_idx = torch.max(predicted_label, axis=1)\n",
    "_, true_label_idx = torch.max(label_torch, axis=1)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(predicted_label.float(), true_label_idx)\n",
    "# corr = (predicted_label_idx == true_label_idx).sum().item()\n",
    "\n",
    "# print(predicted_label)\n",
    "# print(label)\n",
    "\n",
    "# print(predicted_label_idx)\n",
    "# print(true_label_idx)\n",
    "\n",
    "# print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.48535045981407166\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 모델 출력 (로짓)\n",
    "outputs = torch.tensor([[1.5, 2.0, 0.1],   # 샘플 1의 클래스 점수\n",
    "                        [0.5, 1.5, 2.5]])  # 샘플 2의 클래스 점수\n",
    "\n",
    "# 정답 라벨 (클래스 인덱스)\n",
    "labels = torch.tensor([1, 2])  # 첫 번째 샘플 정답은 1번 클래스, 두 번째는 2번 클래스\n",
    "\n",
    "# 손실 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 손실 계산\n",
    "loss = criterion(outputs, labels)\n",
    "print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_idx = torch.max(predicted_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5747, 0.4253],\n",
      "        [0.3924, 0.6076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0, 1],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(predicted_label)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(predicted_label, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m (\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_torch\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(predicted_label, 1)\n",
    "(predicted == label_torch).sum().item()\n",
    "# total_train += labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5317, 0.4683],\n",
       "        [0.5547, 0.4453],\n",
       "        [0.7365, 0.2635],\n",
       "        [0.4336, 0.5664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(signal_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "path_load = 'Y:/MESA_0.7.0/ppg_preprocessed_npy'\n",
    "labels = np.load(os.path.join(path_load, \"label_ins_hc.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.7117, 2.5175, 3.2185,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([1, 0]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.7117, 2.5175, 3.2185,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([1, 0]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55,\n",
       " 64,\n",
       " 58,\n",
       " 15,\n",
       " 65,\n",
       " 160,\n",
       " 12,\n",
       " 164,\n",
       " 8,\n",
       " 185,\n",
       " 57,\n",
       " 146,\n",
       " 172,\n",
       " 63,\n",
       " 182,\n",
       " 134,\n",
       " 159,\n",
       " 7,\n",
       " 6,\n",
       " 54,\n",
       " 28,\n",
       " 117,\n",
       " 93,\n",
       " 169,\n",
       " 126,\n",
       " 112,\n",
       " 97,\n",
       " 128,\n",
       " 144,\n",
       " 67,\n",
       " 22,\n",
       " 56,\n",
       " 69,\n",
       " 171,\n",
       " 82,\n",
       " 101,\n",
       " 115,\n",
       " 154,\n",
       " 186,\n",
       " 29,\n",
       " 37,\n",
       " 81,\n",
       " 175,\n",
       " 60,\n",
       " 155,\n",
       " 35,\n",
       " 130,\n",
       " 158,\n",
       " 85,\n",
       " 47,\n",
       " 70,\n",
       " 176,\n",
       " 161,\n",
       " 113,\n",
       " 44,\n",
       " 98,\n",
       " 180,\n",
       " 49,\n",
       " 51,\n",
       " 162,\n",
       " 137,\n",
       " 86,\n",
       " 191,\n",
       " 188,\n",
       " 89,\n",
       " 127,\n",
       " 166,\n",
       " 77,\n",
       " 193,\n",
       " 30,\n",
       " 107,\n",
       " 40,\n",
       " 20,\n",
       " 36,\n",
       " 120,\n",
       " 32,\n",
       " 73,\n",
       " 3,\n",
       " 184,\n",
       " 124,\n",
       " 11,\n",
       " 62,\n",
       " 23,\n",
       " 78,\n",
       " 72,\n",
       " 190,\n",
       " 90,\n",
       " 116,\n",
       " 106,\n",
       " 147,\n",
       " 94,\n",
       " 132,\n",
       " 52,\n",
       " 38,\n",
       " 152,\n",
       " 88,\n",
       " 83,\n",
       " 156,\n",
       " 149,\n",
       " 80,\n",
       " 192,\n",
       " 79,\n",
       " 91,\n",
       " 189,\n",
       " 10,\n",
       " 123,\n",
       " 122,\n",
       " 66,\n",
       " 135,\n",
       " 108,\n",
       " 0,\n",
       " 74,\n",
       " 183,\n",
       " 45,\n",
       " 136,\n",
       " 39,\n",
       " 95,\n",
       " 187,\n",
       " 129,\n",
       " 18,\n",
       " 125,\n",
       " 27,\n",
       " 114,\n",
       " 111,\n",
       " 148,\n",
       " 121,\n",
       " 178,\n",
       " 61,\n",
       " 139,\n",
       " 46,\n",
       " 143,\n",
       " 174,\n",
       " 109,\n",
       " 4,\n",
       " 99,\n",
       " 141,\n",
       " 163,\n",
       " 50,\n",
       " 68,\n",
       " 41,\n",
       " 181,\n",
       " 2,\n",
       " 13,\n",
       " 170,\n",
       " 96,\n",
       " 76,\n",
       " 110,\n",
       " 196,\n",
       " 43,\n",
       " 105,\n",
       " 140,\n",
       " 177,\n",
       " 153,\n",
       " 194,\n",
       " 34,\n",
       " 53,\n",
       " 151,\n",
       " 179]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signal, label \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# print(signal.shape, label)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label_test \u001b[38;5;129;01min\u001b[39;00m label:\n\u001b[1;32m----> 8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlabel_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[0;32m      9\u001b[0m             cnt_0 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "cnt_0 = 0\n",
    "cnt_1 = 0\n",
    "\n",
    "for signal, label in train_loader:\n",
    "    # print(signal.shape, label)\n",
    "\n",
    "    for label_test in label:\n",
    "        if label_test == 0:\n",
    "            cnt_0 += 1\n",
    "        else:\n",
    "            cnt_1 += 1\n",
    "\n",
    "print(cnt_0, cnt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "path_load = 'Y:/MESA_0.7.0/ppg_preprocessed_npy'\n",
    "labels = np.load(os.path.join(path_load, \"label_ins_hc.npy\")).reshape(-1, 1)\n",
    "\n",
    "# One-hot encoder 생성 및 적용\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "one_hot_encoded = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mone_hot_encoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "one_hot_encoded.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_dataset.gen_dataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.Subset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_dataset import gen_dataset\n",
    "from my_model import SimpleSleepPPGModel, SimpleSleepPPGModel_2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 준비\n",
    "train_dataset = gen_dataset(train_or_test='train')\n",
    "test_dataset = gen_dataset(train_or_test='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "my_model = SimpleSleepPPGModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3305831/(2**12)).__trunc__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1          [-1, 16, 1652916]              64\n",
      "       BatchNorm1d-2          [-1, 16, 1652916]              32\n",
      "         MaxPool1d-3           [-1, 16, 826458]               0\n",
      "            Conv1d-4           [-1, 16, 826458]             784\n",
      "       BatchNorm1d-5           [-1, 16, 826458]              32\n",
      "         MaxPool1d-6           [-1, 16, 413229]               0\n",
      "            Conv1d-7           [-1, 16, 413229]             784\n",
      "       BatchNorm1d-8           [-1, 16, 413229]              32\n",
      "         MaxPool1d-9           [-1, 16, 206614]               0\n",
      "           Conv1d-10           [-1, 32, 103307]           1,568\n",
      "      BatchNorm1d-11           [-1, 32, 103307]              64\n",
      "        MaxPool1d-12            [-1, 32, 51653]               0\n",
      "           Conv1d-13            [-1, 32, 51653]           3,104\n",
      "      BatchNorm1d-14            [-1, 32, 51653]              64\n",
      "        MaxPool1d-15            [-1, 32, 25826]               0\n",
      "           Conv1d-16            [-1, 32, 25826]           3,104\n",
      "      BatchNorm1d-17            [-1, 32, 25826]              64\n",
      "        MaxPool1d-18            [-1, 32, 12913]               0\n",
      "           Conv1d-19             [-1, 64, 6457]           6,208\n",
      "      BatchNorm1d-20             [-1, 64, 6457]             128\n",
      "        MaxPool1d-21             [-1, 64, 3228]               0\n",
      "           Conv1d-22             [-1, 64, 3228]          12,352\n",
      "      BatchNorm1d-23             [-1, 64, 3228]             128\n",
      "        MaxPool1d-24             [-1, 64, 1614]               0\n",
      "           Conv1d-25             [-1, 64, 1614]          12,352\n",
      "      BatchNorm1d-26             [-1, 64, 1614]             128\n",
      "        MaxPool1d-27              [-1, 64, 807]               0\n",
      "           Conv1d-28             [-1, 128, 404]          24,704\n",
      "      BatchNorm1d-29             [-1, 128, 404]             256\n",
      "        MaxPool1d-30             [-1, 128, 202]               0\n",
      "           Conv1d-31             [-1, 128, 202]          49,280\n",
      "      BatchNorm1d-32             [-1, 128, 202]             256\n",
      "        MaxPool1d-33             [-1, 128, 101]               0\n",
      "           Conv1d-34             [-1, 128, 101]          49,280\n",
      "      BatchNorm1d-35             [-1, 128, 101]             256\n",
      "        MaxPool1d-36              [-1, 128, 50]               0\n",
      "           Linear-37                  [-1, 128]         819,328\n",
      "          Dropout-38                  [-1, 128]               0\n",
      "           Linear-39                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 984,610\n",
      "Trainable params: 984,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.61\n",
      "Forward/backward pass size (MB): 1008.62\n",
      "Params size (MB): 3.76\n",
      "Estimated Total Size (MB): 1024.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from my_model import SimpleSleepPPGModel, SimpleSleepPPGModel_2\n",
    "\n",
    "from torchsummary import summary\n",
    "my_model = SimpleSleepPPGModel()\n",
    "net = my_model.cuda()\n",
    "summary(net, (1, 3305831))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 초기화\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleSleepPPGModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for signals, labels in train_loader:\n",
    "        signals, labels = signals.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(signals)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ins_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
