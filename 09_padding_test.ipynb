{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SameConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1):\n",
    "        super(SameConv1d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "            padding=0,  # padding은 수동으로 적용\n",
    "            dilation=dilation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = x.size(-1)\n",
    "\n",
    "        # 패딩 계산\n",
    "        total_padding = max(\n",
    "            0,\n",
    "            (input_size - 1) * self.stride + self.dilation * (self.kernel_size - 1) + 1 - input_size\n",
    "        )\n",
    "        left_padding = total_padding // 2\n",
    "        right_padding = total_padding - left_padding\n",
    "\n",
    "        # 비대칭 패딩 적용\n",
    "        x = F.pad(x, (left_padding, right_padding))\n",
    "        print(x)\n",
    "\n",
    "        # Convolution 적용\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.7394, -0.0121, -0.5791, -1.3157, -0.5678, -0.7415,  2.7017,\n",
      "           0.8354, -0.3386,  0.1396,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000]]])\n",
      "Input size: torch.Size([1, 1, 10]), Output size: torch.Size([1, 5, 10])\n",
      "tensor([[[ 0.7394, -0.0121, -0.5791, -1.3157, -0.5678, -0.7415,  2.7017,\n",
      "           0.8354, -0.3386,  0.1396]]])\n",
      "tensor([[[-0.4368, -0.4368, -0.4368, -0.4368,  0.1561,  0.3450, -0.4368,\n",
      "          -0.4368, -0.4368, -0.4368],\n",
      "         [ 0.2088,  0.2088,  0.2088,  0.2088,  0.0764, -0.2697,  0.2088,\n",
      "           0.2088,  0.2088,  0.2088],\n",
      "         [ 0.1693,  0.1693,  0.1693,  0.1693, -0.1710,  0.7440,  0.1693,\n",
      "           0.1693,  0.1693,  0.1693],\n",
      "         [-0.5284, -0.5284, -0.5284, -0.5284, -0.0797, -0.8991, -0.5284,\n",
      "          -0.5284, -0.5284, -0.5284],\n",
      "         [ 0.3848,  0.3848,  0.3848,  0.3848, -0.0238,  0.1240,  0.3848,\n",
      "           0.3848,  0.3848,  0.3848]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터: Batch size=1, Channels=1, Length=10\n",
    "x = torch.randn(1, 1, 10)\n",
    "\n",
    "# 'same' 패딩 Convolution\n",
    "conv = SameConv1d(in_channels=1, out_channels=5, kernel_size=2, stride=4)\n",
    "\n",
    "output = conv(x)\n",
    "print(f\"Input size: {x.shape}, Output size: {output.shape}\")\n",
    "\n",
    "print(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBnRelu(nn.Module):\n",
    "    def __init__(self,\n",
    "                 ch_in: int,\n",
    "                 ch_out: int,\n",
    "                 kernel: int,\n",
    "                 stride: int,\n",
    "                 is_max_pool: bool,\n",
    "                 dilation: int = 1,\n",
    "                 padding: str = \"no\",\n",
    "                 activation: str = 'relu') -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(ch_in, ch_out, kernel, stride, \n",
    "                              padding=0, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(ch_out)\n",
    "\n",
    "        self.activation = None        \n",
    "        if activation.lower() == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride        \n",
    "        self.dilation = dilation\n",
    "        self.is_max_pool = is_max_pool\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, feat_in: Tensor) -> Tensor:\n",
    "        if self.padding == 'same':\n",
    "            feat_in = self.pad_for_same_size(feat_in, self.kernel, self.stride, self.dilation)\n",
    "\n",
    "        f_map = self.conv(feat_in)\n",
    "        f_map = self.bn(f_map)\n",
    "        if self.activation is not None:\n",
    "            f_map = self.activation(f_map)\n",
    "\n",
    "        if self.is_max_pool:\n",
    "            f_map = self.max_pool(f_map)\n",
    "\n",
    "        return f_map\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_for_same_size(x, kernel_size, stride, dilation):\n",
    "        input_size = x.size(-1)\n",
    "\n",
    "        total_padding = max(\n",
    "            0,\n",
    "            (input_size - 1) * stride + dilation * (kernel_size - 1) + 1 - input_size\n",
    "        )\n",
    "        left_padding = total_padding // 2\n",
    "        right_padding = total_padding - left_padding\n",
    "\n",
    "        # 비대칭 패딩 적용\n",
    "        x_padded = F.pad(x, (left_padding, right_padding))\n",
    "        return x_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Output size: torch.Size([1, 8, 661164])\n",
      " Output size: torch.Size([1, 8, 132230])\n",
      " Output size: torch.Size([1, 8, 44074])\n",
      " Output size: torch.Size([1, 8, 14689])\n",
      " Output size: torch.Size([1, 8, 7343])\n",
      " Output size: torch.Size([1, 8, 3670])\n",
      " Output size: torch.Size([1, 16, 1835])\n",
      " Output size: torch.Size([1, 32, 917])\n",
      " Output size: torch.Size([1, 64, 458])\n",
      " Output size: torch.Size([1, 64, 229])\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터: Batch size=1, Channels=1, Length=10\n",
    "x = torch.randn(1, 1, 3305831)\n",
    "\n",
    "# 'same' 패딩 Convolution\n",
    "conv_list = [\n",
    "    ConvBnRelu(1, 8, 15, 5, is_max_pool=False),\n",
    "    ConvBnRelu(8, 8, 15, 5, is_max_pool=False),\n",
    "\n",
    "    ConvBnRelu(8, 8, 10, 3, is_max_pool=False), \n",
    "    ConvBnRelu(8, 8, 10, 3, is_max_pool=False), \n",
    "\n",
    "    ConvBnRelu(8, 8, 5, 2, is_max_pool=False),\n",
    "    ConvBnRelu(8, 8, 5, 2, is_max_pool=False),\n",
    "\n",
    "    ConvBnRelu(8, 16, 2, 2, is_max_pool=False),\n",
    "    ConvBnRelu(16, 32, 2, 2, is_max_pool=False),\n",
    "    ConvBnRelu(32, 64, 2, 2, is_max_pool=False),\n",
    "    ConvBnRelu(64, 64, 2, 2, is_max_pool=False),\n",
    "]\n",
    "\n",
    "output = x\n",
    "\n",
    "for _conv in conv_list:\n",
    "    output = _conv(output)\n",
    "    print(f\" Output size: {output.shape}\")\n",
    "\n",
    "# print(x)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 8, 661164]             120\n",
      "       BatchNorm1d-2            [-1, 8, 661164]              16\n",
      "              ReLU-3            [-1, 8, 661164]               0\n",
      "        ConvBnRelu-4            [-1, 8, 661164]               0\n",
      "            Conv1d-5            [-1, 8, 132230]             960\n",
      "       BatchNorm1d-6            [-1, 8, 132230]              16\n",
      "              ReLU-7            [-1, 8, 132230]               0\n",
      "        ConvBnRelu-8            [-1, 8, 132230]               0\n",
      "            Conv1d-9             [-1, 8, 44074]             640\n",
      "      BatchNorm1d-10             [-1, 8, 44074]              16\n",
      "             ReLU-11             [-1, 8, 44074]               0\n",
      "       ConvBnRelu-12             [-1, 8, 44074]               0\n",
      "           Conv1d-13             [-1, 8, 14689]             640\n",
      "      BatchNorm1d-14             [-1, 8, 14689]              16\n",
      "             ReLU-15             [-1, 8, 14689]               0\n",
      "       ConvBnRelu-16             [-1, 8, 14689]               0\n",
      "           Conv1d-17              [-1, 8, 7343]             320\n",
      "      BatchNorm1d-18              [-1, 8, 7343]              16\n",
      "             ReLU-19              [-1, 8, 7343]               0\n",
      "       ConvBnRelu-20              [-1, 8, 7343]               0\n",
      "           Conv1d-21              [-1, 8, 3670]             320\n",
      "      BatchNorm1d-22              [-1, 8, 3670]              16\n",
      "             ReLU-23              [-1, 8, 3670]               0\n",
      "       ConvBnRelu-24              [-1, 8, 3670]               0\n",
      "           Conv1d-25             [-1, 16, 1835]             256\n",
      "      BatchNorm1d-26             [-1, 16, 1835]              32\n",
      "             ReLU-27             [-1, 16, 1835]               0\n",
      "       ConvBnRelu-28             [-1, 16, 1835]               0\n",
      "           Conv1d-29              [-1, 32, 917]           1,024\n",
      "      BatchNorm1d-30              [-1, 32, 917]              64\n",
      "             ReLU-31              [-1, 32, 917]               0\n",
      "       ConvBnRelu-32              [-1, 32, 917]               0\n",
      "           Conv1d-33              [-1, 64, 458]           4,096\n",
      "      BatchNorm1d-34              [-1, 64, 458]             128\n",
      "             ReLU-35              [-1, 64, 458]               0\n",
      "       ConvBnRelu-36              [-1, 64, 458]               0\n",
      "           Conv1d-37              [-1, 64, 229]           8,192\n",
      "      BatchNorm1d-38              [-1, 64, 229]             128\n",
      "             ReLU-39              [-1, 64, 229]               0\n",
      "       ConvBnRelu-40              [-1, 64, 229]               0\n",
      "           Linear-41                   [-1, 32]         469,024\n",
      "          Dropout-42                   [-1, 32]               0\n",
      "           Linear-43                    [-1, 2]              66\n",
      "================================================================\n",
      "Total params: 486,106\n",
      "Trainable params: 486,106\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.61\n",
      "Forward/backward pass size (MB): 213.87\n",
      "Params size (MB): 1.85\n",
      "Estimated Total Size (MB): 228.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from my_model import SimpleSleepPPGModel\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "net = SimpleSleepPPGModel().to(device)\n",
    "model = net.cuda()\n",
    "summary(net, (1, 3305831))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ins_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
