{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom Dataset 생성\n",
    "class FakePPGDataset(Dataset):\n",
    "    def __init__(self, num_samples=1000, signal_length=250, num_classes=2, sampling_rate=34):\n",
    "        np.random.seed(42)\n",
    "        self.num_samples = num_samples\n",
    "        self.signal_length = signal_length\n",
    "        self.num_classes = num_classes\n",
    "        self.sampling_rate = sampling_rate\n",
    "\n",
    "        # 가짜 PPG 데이터 생성 (정규 분포)\n",
    "        self.data = np.random.normal(0, 1, (num_samples, signal_length))\n",
    "        \n",
    "        # 라벨 생성 (0 또는 1)\n",
    "        self.labels = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        # PyTorch 텐서로 변환\n",
    "        return torch.tensor(signal, dtype=torch.float32).unsqueeze(0), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_dataset = FakePPGDataset(num_samples=800)\n",
    "test_dataset = FakePPGDataset(num_samples=200)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleSleepPPGModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):  # num_classes는 분류할 클래스 수\n",
    "        super(SimpleSleepPPGModel, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Batch Normalization\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        # MaxPooling Layers\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(64 * 62, 128)  # 조정된 입력 크기 (64 feature maps, 길이 62로 감소)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional Layers with ReLU, BatchNorm, and MaxPooling\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # Conv1 -> ReLU -> BatchNorm -> MaxPooling\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # Conv2 -> ReLU -> BatchNorm -> MaxPooling\n",
    "        x = F.relu(self.bn3(self.conv3(x)))            # Conv3 -> ReLU -> BatchNorm (마지막 레이어는 Pooling 생략 가능)\n",
    "        \n",
    "        # Flattening\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))  # Fully Connected Layer + ReLU\n",
    "        x = self.dropout(x)      # Dropout\n",
    "        x = self.fc2(x)          # Output Layer (분류)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.8067\n",
      "Epoch [2/10], Loss: 0.6601\n",
      "Epoch [3/10], Loss: 0.6136\n",
      "Epoch [4/10], Loss: 0.5261\n",
      "Epoch [5/10], Loss: 0.4366\n",
      "Epoch [6/10], Loss: 0.3575\n",
      "Epoch [7/10], Loss: 0.2594\n",
      "Epoch [8/10], Loss: 0.2180\n",
      "Epoch [9/10], Loss: 0.1173\n",
      "Epoch [10/10], Loss: 0.0853\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 초기화\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleSleepPPGModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for signals, labels in train_loader:\n",
    "        signals, labels = signals.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(signals)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ins_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
